{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":673681,"sourceType":"datasetVersion","datasetId":339734}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load dataset\nratings = pd.read_csv('/kaggle/input/bookcrossing-dataset/Ratings.csv', sep=';', on_bad_lines='skip')\n\n# Pivot to create user-item matrix\nuser_item_matrix = ratings.pivot(index='User-ID', columns='ISBN', values='Rating').fillna(0)\n\n# Normalize preferences (optional)\nuser_item_matrix = (user_item_matrix - user_item_matrix.mean(axis=1).values[:, None])\nimport networkx as nx\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Create graph for a user based on their preferences\ndef create_user_graph(preferences):\n    graph = nx.Graph()\n    for i, item1 in enumerate(preferences):\n        for j, item2 in enumerate(preferences):\n            if i != j and preferences[i] > 0 and preferences[j] > 0:\n                graph.add_edge(i, j, weight=preferences[i] * preferences[j])\n    return graph\n\n# Compute Top-K similarities\ndef top_k_similarities(matrix, k=5):\n    similarities = cosine_similarity(matrix)\n    top_k = np.argsort(-similarities, axis=1)[:, :k]\n    return top_k\n\n# Compute GNN-based similarity (placeholder function)\ndef compute_gnn_similarity(graph1, graph2, top_k_indices):\n    # Example: simple cosine similarity on graph adjacency matrices\n    adj1 = nx.to_numpy_matrix(graph1)\n    adj2 = nx.to_numpy_matrix(graph2)\n    return cosine_similarity(adj1, adj2)[0, 0]\n    # Create graphs for all users\nuser_graphs = [create_user_graph(user_item_matrix.iloc[i].values) for i in range(user_item_matrix.shape[0])]\n\n# Compute pairwise similarities\nsimilarities = []\nfor i in range(len(user_graphs)):\n    for j in range(len(user_graphs)):\n        if i != j:\n            top_k_indices = top_k_similarities(user_item_matrix.values, k=5)\n            sim = compute_gnn_similarity(user_graphs[i], user_graphs[j], top_k_indices)\n            similarities.append((i, j, sim))\n# Create graph for clustering\nG = nx.Graph()\nG.add_nodes_from(range(len(user_graphs)))\nG.add_weighted_edges_from(similarities)\n\n# Dominant Set Clustering\ndef dominant_set_clustering(graph, max_clusters=5):\n    clusters = []\n    nodes = list(graph.nodes())\n    while nodes and len(clusters) < max_clusters:\n        dominant_set = nx.maximal_independent_set(graph.subgraph(nodes))\n        clusters.append(dominant_set)\n        nodes = list(set(nodes) - set(dominant_set))\n    return clusters\n\n# Get clusters\nclusters = dominant_set_clustering(G)\nprint(\"Clusters:\", clusters)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T21:47:56.074525Z","iopub.execute_input":"2024-11-24T21:47:56.075049Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/725115289.py:8: PerformanceWarning: The following operation may generate 35854757348 cells in the resulting pandas object.\n  user_item_matrix = ratings.pivot(index='User-ID', columns='ISBN', values='Rating').fillna(0)\n","output_type":"stream"}],"execution_count":null}]}